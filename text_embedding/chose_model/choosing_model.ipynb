{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import cohere\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "import openai\n",
    "from openai import OpenAI\n",
    "from tqdm.notebook import tqdm\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "# initialize openai\n",
    "os.environ['OPENAI_API_KEY']= \"\"\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]\n",
    "\n",
    "# initialize cohere\n",
    "os.environ[\"CO_API_KEY\"] = \"\"\n",
    "co = cohere.Client()\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>id</th>\n",
       "      <th>duplicated_questions</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Astrology: I am a Capricorn Sun Cap moon and c...</td>\n",
       "      <td>11</td>\n",
       "      <td>[12]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I'm a triple Capricorn (Sun, Moon and ascendan...</td>\n",
       "      <td>12</td>\n",
       "      <td>[11]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>How can I be a good geologist?</td>\n",
       "      <td>15</td>\n",
       "      <td>[16]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What should I do to be a great geologist?</td>\n",
       "      <td>16</td>\n",
       "      <td>[15]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>How do I read and find my YouTube comments?</td>\n",
       "      <td>23</td>\n",
       "      <td>[24]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  id duplicated_questions  \\\n",
       "0  Astrology: I am a Capricorn Sun Cap moon and c...  11                 [12]   \n",
       "1  I'm a triple Capricorn (Sun, Moon and ascendan...  12                 [11]   \n",
       "2                     How can I be a good geologist?  15                 [16]   \n",
       "3          What should I do to be a great geologist?  16                 [15]   \n",
       "4        How do I read and find my YouTube comments?  23                 [24]   \n",
       "\n",
       "   length  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"/Users/parksehun/Desktop/project_workplace/vectordb/datasets/quora_dataset.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How can I be a good geologist?\n"
     ]
    }
   ],
   "source": [
    "text1 = df.loc[2, 'text']\n",
    "print(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What should I do to be a great geologist?\n"
     ]
    }
   ],
   "source": [
    "text2 = df.loc[3, 'text']\n",
    "print(text2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(txt_list, provider='openai'):\n",
    "    if provider=='openai':\n",
    "        client = OpenAI()\n",
    "\n",
    "        response = client.embeddings.create(\n",
    "        input=txt_list,\n",
    "        model=\"text-embedding-3-small\")\n",
    "        responses = [r.embedding for r in response.data]\n",
    "\n",
    "        return responses\n",
    "    \n",
    "    elif provider=='cohere':\n",
    "        doc_embeds = co.embed(\n",
    "        txt_list,\n",
    "        input_type=\"search_document\",\n",
    "        model=\"embed-english-v3.0\")\n",
    "        return doc_embeds.embeddings\n",
    "    else:\n",
    "        assert False, \"Double check provider name\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb1 = create_embeddings(df.loc[2, 'text'])\n",
    "emb2 = create_embeddings(df.loc[3, 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine 유사도 : 0.9152851389168591.\n",
      "사용된 문장 : \n",
      "How can I be a good geologist?\n",
      "What should I do to be a great geologist?\n"
     ]
    }
   ],
   "source": [
    "# simarity between two embeddings\n",
    "print(\"Cosine 유사도 : {}.\\n사용된 문장 : \\n{}\\n{}\".format(cosine_similarity(emb1[0], emb2[0]), text1, text2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine 유사도 : 0.18171728610851556.\n",
      "사용된 문장 : \n",
      "How can I be a good geologist?\n",
      "How do I read and find my YouTube comments?\n"
     ]
    }
   ],
   "source": [
    "text3 = df.loc[4, 'text']\n",
    "\n",
    "emb3 = create_embeddings(text3)\n",
    "print(\"Cosine 유사도 : {}.\\n사용된 문장 : \\n{}\\n{}\".format(cosine_similarity(emb1[0], emb3[0]), text1, text3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine 유사도 : 0.27956845199343094.\n",
      "사용된 문장 : \n",
      "How can I be a good geologist?\n",
      "What can make Physics easy to learn?\n"
     ]
    }
   ],
   "source": [
    "text4 = df.loc[6, 'text']\n",
    "\n",
    "emb3 = create_embeddings(text4)\n",
    "print(\"Cosine 유사도 : {}.\\n사용된 문장 : \\n{}\\n{}\".format(cosine_similarity(emb1[0], emb3[0]), text1, text4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e5 embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec85112bc8c14393a1122852f424370c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/314 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbe52dadf60e4f98b33e56d138d9f54a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf13b0859814463ea77335e3cc24f838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9143ef770174f358c3482ed61b6bfab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ac5062cba84c7ba92354ca3f146612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/650 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b441f6b1ecd48ffb3ff85e720ec633e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load gpu if possible\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_id = \"intfloat/e5-base-v2\"\n",
    "\n",
    "# init tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id).to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_e5_emb(docs, model):\n",
    "    \"\"\"\n",
    "    e5 embedding 모델을 활용하여 임베딩 벡터 생성\n",
    "    \"\"\"\n",
    "    docs = [f\"query: {d}\" for d in docs]\n",
    "    # tokenize\n",
    "    tokens = tokenizer(\n",
    "        docs, padding=True, max_length=512, truncation=True, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "    with torch.no_grad():\n",
    "        out = model(**tokens)\n",
    "        last_hidden = out.last_hidden_state.masked_fill( # from last hidden state\n",
    "            ~tokens[\"attention_mask\"][..., None].bool(), 0.0\n",
    "        )\n",
    "        # average out embeddings per token (non-padding)\n",
    "        doc_embeds = last_hidden.sum(dim=1) / tokens[\"attention_mask\"].sum(dim=1)[..., None]\n",
    "    return doc_embeds.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df.text.tolist()\n",
    "batch_size = 128\n",
    "\n",
    "for i in tqdm(range(0, len(data), batch_size)):\n",
    "    i_end = min(len(data), i+batch_size)\n",
    "    data_batch = data[i:i_end]\n",
    "     # embed current batch\n",
    "    embed_batch = create_e5_emb(data_batch)\n",
    "    if i == 0:\n",
    "        emb3 = embed_batch.copy()\n",
    "    else:\n",
    "        emb3 = np.concatenate([emb3, embed_batch.copy()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vecvenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
